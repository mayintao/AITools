import os
# è®¾ç½® huggingface çš„ç¼“å­˜è·¯å¾„ï¼ˆä½ å·²ç»è®¾ç½®äº†ï¼‰
os.environ["TRANSFORMERS_CACHE"] = "/tmp/huggingface"
os.environ["HF_HOME"] = "/tmp/huggingface"
# å°† PaddleOCR çš„æ¨¡å‹ç¼“å­˜è·¯å¾„æŒ‡å‘ /tmp ä¸‹
os.environ["PADDLEOCR_HOME"] = "/tmp/paddleocr_models"
os.makedirs("/tmp/paddleocr_models", exist_ok=True)

import uuid
import time
from PIL import Image, ImageDraw, ImageFont
from flask_cors import CORS
from paddleocr import PaddleOCR
from flask import jsonify, Flask, request
from transformers import MarianMTModel, MarianTokenizer
import base64
from io import BytesIO
import logging
# å­—å…¸åˆå§‹åŒ–æ—¶è‡ªåŠ¨èµ‹é»˜è®¤å€¼
from collections import defaultdict 
import traceback

# åˆ›å»ºç‹¬ç«‹è™šæ‹Ÿç¯å¢ƒ: python -m venv venv
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ: venv\Scripts\activate

app = Flask(__name__)
CORS(app)

# è®¾ç½®æ—¥å¿—è®°å½•
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
)

# è¯·æ±‚è®¡æ•°å™¨
request_counter = defaultdict(int)
# å…¨å±€è®¡æ•°å™¨
translate_image_counter = 0


# åˆå§‹åŒ– OCR
ocr = PaddleOCR(
    use_doc_orientation_classify=False,
    use_doc_unwarping=False,
    use_textline_orientation=False,
    det_model_dir='/tmp/paddleocr_models/det',
    rec_model_dir='/tmp/paddleocr_models/rec',
    cls_model_dir='/tmp/paddleocr_models/cls'
)

def image_to_base64(img_path):
    img = Image.open(img_path).convert('RGB')
    buffered = BytesIO()
    img.save(buffered, format="JPEG")
    return base64.b64encode(buffered.getvalue()).decode("utf-8")

# åŠ è½½ä¸­æ–‡å­—ä½“
def load_chinese_font(size=24):
    try:
        print("å°è¯•åŠ è½½ä¸­æ–‡å­—ä½“ simfang.ttf")
        return ImageFont.truetype("simfang.ttf", size=size)
    except Exception as e:
        print(f"âš ï¸ åŠ è½½ä¸­æ–‡å­—ä½“å¤±è´¥: {e}")
        return ImageFont.load_default()


# æ”¯æŒçš„è¯­è¨€å¯¹åŠå…¶æ¨¡å‹
MODEL_MAP = {
    "zh-en": "Helsinki-NLP/opus-mt-zh-en",
    "en-zh": "Helsinki-NLP/opus-mt-en-zh",
    "zh-de": "Helsinki-NLP/opus-mt-zh-de",
    "de-zh": "Helsinki-NLP/opus-mt-de-zh",
    "ja-en": "Helsinki-NLP/opus-mt-ja-en",
    "en-ja": "Helsinki-NLP/opus-mt-en-jap",
}

# æ¨¡å‹ç¼“å­˜
models = {}
tokenizers = {}


# å¯åŠ¨æ—¶é¢„åŠ è½½æ‰€æœ‰æ¨¡å‹ï¼Œé¿å…æ¯æ¬¡éƒ½åŠ è½½æ¨¡å‹ï¼Œç‰¹åˆ«è€—æ—¶ï¼
def preload_models():
    print("ğŸš€ æ­£åœ¨é¢„åŠ è½½æ‰€æœ‰ç¿»è¯‘æ¨¡å‹...")
    for model_name in set(MODEL_MAP.values()):
        try:
            # å³åœ¨ models å’Œ tokenizers ä¸­ï¼Œå°±ç›´æ¥è¿”å›ç¼“å­˜ï¼Œä¸å†æ‰§è¡Œ from_pretrained(...)
            tokenizer = MarianTokenizer.from_pretrained(model_name)
            model = MarianMTModel.from_pretrained(model_name)
            tokenizers[model_name] = tokenizer
            models[model_name] = model
            print(f"âœ… æ¨¡å‹å·²åŠ è½½: {model_name}")
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥: {model_name} -> {e}")


def load_model(model_name):
      # è·å–å·²ç¼“å­˜çš„æ¨¡å‹å’Œ tokenizerï¼Œå¦‚æœä¸å­˜åœ¨å°±åŠ è½½ï¼ˆå®¹é”™ï¼‰
    if model_name not in models or model_name not in tokenizers:
        logging.warning(f"âš ï¸ æ¨¡å‹ {model_name} æœªé¢„åŠ è½½ï¼Œæ­£åœ¨åŠ¨æ€åŠ è½½ï¼")
        tokenizer = MarianTokenizer.from_pretrained(model_name)
        model = MarianMTModel.from_pretrained(model_name)
        tokenizers[model_name] = tokenizer
        models[model_name] = model
    return tokenizers[model_name], models[model_name]


def translate_text(text: str, src_lang: str, tgt_lang: str):
    start_time = time.time()
    
    lang_key = f"{src_lang}-{tgt_lang}"
    request_counter[lang_key] += 1
    model_name = MODEL_MAP.get(lang_key)

    if not model_name:
        return jsonify({"error": f"Translation from {src_lang} to {tgt_lang} is not supported."}), 400

    try:
        tokenizer, model = load_model(model_name)
        inputs = tokenizer([text], return_tensors="pt", padding=True, truncation=True, max_length=512)
        translated = model.generate(**inputs, max_length=512)
        translated_text = tokenizer.batch_decode(translated, skip_special_tokens=True)[0]

        elapsed = round((time.time() - start_time) * 1000, 2)
        client_ip = request.remote_addr or "unknown"

        # æ—¥å¿—è¾“å‡º
        logging.info(
            f"[{client_ip}] {src_lang}->{tgt_lang} | \"{text[:30]}\" -> \"{translated_text[:30]}\" | {elapsed}ms | Total: {request_counter[lang_key]}"
        )
        
    except Exception as e:
        print(str(e))
        return jsonify({"error": str(e)}), 500

    return jsonify({
        "translated_text": translated_text,
        "source_language": src_lang,
        "target_language": tgt_lang
    })


def translate_image(image_path: str, src_lang: str, tgt_lang: str):
    global translate_image_counter
    translate_image_counter += 1
    request_id = uuid.uuid4().hex[:8]

    lang_key = f"{src_lang}-{tgt_lang}"
    print(lang_key)
    model_name = MODEL_MAP.get(lang_key)
    print(model_name)
    if not model_name:
        logging.warning(f"[{request_id}] âŒ ä¸æ”¯æŒçš„è¯­è¨€å¯¹: {lang_key}")
        return jsonify({"error": f"Unsupported language pair: {lang_key}"}), 400

    try:
        # ocr è¯†åˆ«
        print('ocr è¯†åˆ« start')
        result = ocr.ocr(image_path)

        original_img = Image.open(image_path).convert("RGB")
        draw = ImageDraw.Draw(original_img)

        print(f"[DEBUG] tgt_lang = '{tgt_lang}'")
        if tgt_lang.strip().lower() == 'zh':
            print('goto load_chinese_font')
            font = load_chinese_font(size=24)
        else:
            print('load_default font')
            font = ImageFont.load_default()
        
        translated_results = []
        ocr_result = result[0]

        for box, (orig_text, score) in ocr_result:
            logging.info(f"orig_text: {orig_text}")
            try:
                tokenizer, model = load_model(model_name)
                inputs = tokenizer([orig_text], return_tensors="pt", padding=True, truncation=True, max_length=512)
                translated = model.generate(**inputs, max_length=512)
                translated_text = tokenizer.batch_decode(translated, skip_special_tokens=True)[0]
                logging.info(f"[{request_id}] ğŸ” ç¿»è¯‘: {translated_text}")
        
                translated_results.append({
                    'poly': box,
                    'original': orig_text,
                    'translated': translated_text
                })
        
                draw.polygon(box, outline="red", width=1)
                draw.text((box[0][0], box[0][1] - 15), translated_text, fill="blue", font=font)
            except Exception as e:
                logging.error(f"[{request_id}] â— ç¿»è¯‘å¤±è´¥: {e}")
        
        buffered = BytesIO()
        original_img.save(buffered, format="JPEG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")
        print(f"[{request_id}] ğŸ–¼ï¸ å›¾åƒç¿»è¯‘å®Œæˆï¼ŒæˆåŠŸç”Ÿæˆ base64 å›¾åƒ")
        return jsonify({
            "image_base64": img_base64
        })

    except Exception as e:
        logging.error(f"[{request_id}] â— æ•´ä½“ç¿»è¯‘å¤±è´¥: {str(e)}")
        traceback.print_exc()
        return jsonify({"error": f"OCR error: {str(e)}"}), 500


# æ–‡å­—ç¿»è¯‘ post
@app.route("/ai/api_translate_text", methods=["POST"])
def api_translate_text():
    
    data = request.get_json()
    text = data.get("text", "")
    src_lang = data.get("src_lang", "")
    tgt_lang = data.get("tgt_lang", "")
    print(text,src_lang,tgt_lang)

    if not text or not src_lang or not tgt_lang:
        return jsonify({"error": "text, src_lang, tgt_lang are required"}), 400

    try:
        results = translate_text(text, src_lang, tgt_lang)
        print(results)
        return results
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# æ–‡å­—ç¿»è¯‘ get
# https://yintao127-translate.hf.space/ai/api_translate_text_g?text=ä½ å¥½&src_lang=zh&tgt_lang=en
@app.route("/ai/api_translate_text_g", methods=["GET"])
def api_translate_text_g():
    
    text = request.args.get("text", "")
    src_lang = request.args.get("src_lang", "")
    tgt_lang = request.args.get("tgt_lang", "")
    print(text,src_lang,tgt_lang)

    if not text or not src_lang or not tgt_lang:
        return jsonify({"error": "text, src_lang, tgt_lang are required"}), 400

    try:
        results = translate_text(text, src_lang, tgt_lang)
        print(results)
        return results
    except Exception as e:
        return jsonify({"error": str(e)}), 500
    

        
# å›¾ç‰‡ç¿»è¯‘
@app.route("/ai/api_translate_image", methods=["POST"])
def api_translate_image():
    
    if 'image' not in request.files:
        return jsonify({"error": "No image provided"}), 400
    file = request.files['image']
    uid = uuid.uuid4().hex
    logging.info(uid)
    filename = f"{uid}.jpg"
    filepath = os.path.join("/tmp", filename)
    logging.info(filepath)

    src_lang = request.form.get("src_lang")
    tgt_lang = request.form.get("tgt_lang")
    logging.info(tgt_lang)
    
    if not src_lang or not tgt_lang:
        return jsonify({"error": "src_lang, tgt_lang are required"}), 400
    file.save(filepath)
    result = translate_image(filepath, src_lang, tgt_lang)
    # æ¸…ç†ä¸Šä¼ å›¾
    if os.path.exists(filepath):
        os.remove(filepath)
    return result


# test
# https://yintao127-translate.hf.space/ai/api_test_g
@app.route("/ai/api_test_g", methods=["GET"])
def api_test_g():
    return jsonify({"test": "ok!"})


# æŸ¥çœ‹å½“å‰ç¿»è¯‘ç»Ÿè®¡
# https://yintao127-translate.hf.space/ai/api_translate_stats
@app.route("/ai/api_translate_stats", methods=["GET"])
def api_translate_stats():
    return jsonify(dict(request_counter))


# æŸ¥çœ‹æ€»è¯·æ±‚æ¬¡æ•°æ¥å£ï¼ˆç”¨äºçŠ¶æ€é¡µï¼‰
# https://yintao127-translate.hf.space/ai/api_translate_image_status
@app.route("/ai/api_translate_image_status", methods=["GET"])
def api_translate_image_status():
    return jsonify({"image_translate_requests": translate_image_counter})


# å¯åŠ¨æ—¶ç«‹å³åŠ è½½
preload_models()

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=7860)
